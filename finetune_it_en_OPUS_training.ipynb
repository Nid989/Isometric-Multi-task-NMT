{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune it-en OPUS training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07f62b250c6d40228dbea2de26dc7700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86980b994fe54339bf9bf78b4675258a",
              "IPY_MODEL_3ef858ca822445289fe1515a21503605",
              "IPY_MODEL_62db89dfb19f42bc838085c049e13ce9"
            ],
            "layout": "IPY_MODEL_918d47c031434ca9b2405279ee113e22"
          }
        },
        "86980b994fe54339bf9bf78b4675258a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d312ad1bdd945b2ab512478b21da3e8",
            "placeholder": "​",
            "style": "IPY_MODEL_4082eff73a6a4916b614d53f683639a0",
            "value": "100%"
          }
        },
        "3ef858ca822445289fe1515a21503605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945df4bf188240eb87b028e4963bc0f8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb3c306eb019431e9fc18c60f41a84c4",
            "value": 1
          }
        },
        "62db89dfb19f42bc838085c049e13ce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb9c58d407da4d649ffc390b4329eea9",
            "placeholder": "​",
            "style": "IPY_MODEL_e9d97d9bf8e149518d293ef3cf3be4d7",
            "value": " 1/1 [00:00&lt;00:00,  6.67ba/s]"
          }
        },
        "918d47c031434ca9b2405279ee113e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d312ad1bdd945b2ab512478b21da3e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4082eff73a6a4916b614d53f683639a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "945df4bf188240eb87b028e4963bc0f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb3c306eb019431e9fc18c60f41a84c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb9c58d407da4d649ffc390b4329eea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d97d9bf8e149518d293ef3cf3be4d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nid989/Isometric-Multi-task-NMT/blob/main/finetune_it_en_OPUS_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yPpIQCUTu9pf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# un-comment below, while working on colab.\n",
        "!pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece] wandb boto3 --quiet \n",
        "!pip install -U nltk # upgrade current version of NLTK"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, MarianMTModel, MarianTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "from datasets import load_dataset, load_metric\n",
        "import numpy as np\n",
        "import datasets\n",
        "import boto3\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "# from tqdm.notebook import tqdm\n",
        "from tqdm import tqdm \n",
        "import wandb\n",
        "import logging\n",
        "import pandas as pd "
      ],
      "metadata": {
        "id": "1sNQTEXAwBB-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for logging loss to wandb.ai\n",
        "access_key = \"c7deb1bb77ce9433eb246d460385f363659145a8\" # enter wandb secret_accces_key\n",
        "wandb.login(key=access_key)   "
      ],
      "metadata": {
        "id": "3f0qpSQnwM1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5226cf97-2700-4bb4-b45d-fcf838c27c83"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "raw_train_datasets = load_dataset(\"enimai/MuST-C-it\", split=\"train[:50]\")\n",
        "raw_validation_datasets = load_dataset(\"enimai/MuST-C-it\", split=\"validation[:50]\")\n",
        "sacrebleu = load_metric(\"sacrebleu\")\n",
        "meteor = load_metric('meteor')"
      ],
      "metadata": {
        "id": "SS5bSKnSwOSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf26944d-163a-488b-88c5-c28d717891e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration enimai--MuST-C-it-7022eab0bf68926b\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/enimai--MuST-C-it-7022eab0bf68926b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "Using custom data configuration enimai--MuST-C-it-7022eab0bf68926b\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/enimai--MuST-C-it-7022eab0bf68926b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset description\n",
        "print(f\"train: {raw_train_datasets}\")\n",
        "print(f\"validation: {raw_validation_datasets}\")"
      ],
      "metadata": {
        "id": "luBld-SZwSPc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f99207d-be2f-4aa1-be70-e2d525b7d94f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: Dataset({\n",
            "    features: ['en', 'it'],\n",
            "    num_rows: 50\n",
            "})\n",
            "validation: Dataset({\n",
            "    features: ['en', 'it'],\n",
            "    num_rows: 50\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_lang = \"en\"\n",
        "target_lang = \"it\""
      ],
      "metadata": {
        "id": "CxFg2v2I-j2t"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-trained model checkpoints\n",
        "train_model_checkpoints = f\"Helsinki-NLP/opus-mt-en-it\""
      ],
      "metadata": {
        "id": "03uF-V5DwfBJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the MarianMT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(train_model_checkpoints, src_lang=\"en_XX\", tgt_lang=\"de_DE\")"
      ],
      "metadata": {
        "id": "SA8Wp9-xwiZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_verbosity(input_list, target_list):\n",
        "  \"\"\"\n",
        "  input: list of source & target sequences\n",
        "  output: processed source sequence based on the calculated length ratios \n",
        "  \"\"\"\n",
        "  processed_input = []\n",
        "  for input, target in zip(input_list, target_list):\n",
        "    ts_ratio = len(target)/len(input)\n",
        "    if ts_ratio < 0.95:\n",
        "      prefix = \"short\"\n",
        "    elif ts_ratio >= 0.95 and ts_ratio <= 1.10:\n",
        "      prefix = \"normal\"\n",
        "    else:\n",
        "      prefix = \"long\"\n",
        "    input = prefix + \" \" + input\n",
        "    processed_input.append(input)\n",
        "  return processed_input"
      ],
      "metadata": {
        "id": "_HRpnd8vxUGJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess MUST-C dataset\n",
        "max_input_length = 128 \n",
        "max_target_length = 128\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[source_lang]\n",
        "    targets = examples[target_lang]\n",
        "    inputs = add_verbosity(inputs, targets) # append appropriate prompts \n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "    # setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "UGTxkmTjxXzy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize raw data\n",
        "tokenized_train_datasets = raw_train_datasets.map(preprocess_function, batched=True)\n",
        "tokenized_validation_datasets = raw_train_datasets.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "oB05-avda30v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training procedure\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(train_model_checkpoints)"
      ],
      "metadata": {
        "id": "xYHxQZQ_a5NW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32 # change batch-size according to GPU availability \n",
        "model_name = train_model_checkpoints.split(\"/\")[-1]\n",
        "epoch = 3\n",
        "\n",
        "# define training model arguments\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}-testing\",\n",
        "    learning_rate=0.0003,\n",
        "    lr_scheduler_type=\"linear\",\n",
        "    warmup_ratio=0.06,\n",
        "    optim=\"adafactor\",\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=epoch,\n",
        "    report_to=\"wandb\",\n",
        "    save_total_limit=1,\n",
        "    predict_with_generate=True    \n",
        ")\n",
        "\n",
        "# initialize data-collator\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
      ],
      "metadata": {
        "id": "nXzwj7Pla7EG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40973336-97f2-454c-e72e-33e37c70e54d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "    \n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "    sacrebleu_result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    meteor_result = meteor.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\n",
        "        \"bleu\": sacrebleu_result[\"score\"],\n",
        "        \"meteor\": meteor_result[\"meteor\"]\n",
        "    }\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    print(result)\n",
        "    return result"
      ],
      "metadata": {
        "id": "tqcZ2c-Ja73m"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the trainer module\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train_datasets,\n",
        "    eval_dataset=tokenized_validation_datasets,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")"
      ],
      "metadata": {
        "id": "X6fvaFlta8ld"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "YrrtwfZ7a9Yc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compress model checkpoint directory\n",
        "model_checkpoint_directory = f\"{model_name}-finetuned-{source_lang}-to-{target_lang}-testing\"\n",
        "print(model_checkpoint_directory)\n",
        "shutil.make_archive(model_checkpoint_directory, \"zip\", model_checkpoint_directory)"
      ],
      "metadata": {
        "id": "Qf86GU8glURb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session = boto3.Session(\n",
        "    aws_access_key_id='AKIA4QB2WTN5YQGLD77G',\n",
        "    aws_secret_access_key='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',\n",
        ")\n",
        "s3 = session.resource('s3')\n",
        "key = f\"{epoch}_{model_checkpoint_directory}\"\n",
        "filename = f\"{model_checkpoint_directory}.zip\"\n",
        "print(key)\n",
        "s3.meta.client.upload_file(Bucket='tsd2022', Key=key, Filename=filename)"
      ],
      "metadata": {
        "id": "Tvnix9leaTmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete checkpoint directory\n",
        "current_directory = os.getcwd()\n",
        "path_to_directory = os.path.join(current_directory, model_checkpoint_directory)\n",
        "shutil.rmtree(path_to_directory)"
      ],
      "metadata": {
        "id": "xDVfaecBdtDo"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete zip file\n",
        "current_directory = os.getcwd()\n",
        "path_to_zip_file = os.path.join(current_directory, filename)\n",
        "os.remove(path_to_zip_file)"
      ],
      "metadata": {
        "id": "XHZDzdqRd8uv"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "vlMpkaHxJvdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "raw_test_datasets = load_dataset(\"enimai/MuST-C-it\", split=\"test[:50]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Aq90cEJvPu",
        "outputId": "7b820a0a-d33e-409d-b755-4055cc073ca8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration enimai--MuST-C-it-7022eab0bf68926b\n",
            "Reusing dataset csv (/root/.cache/huggingface/datasets/csv/enimai--MuST-C-it-7022eab0bf68926b/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = boto3.Session(\n",
        "    aws_access_key_id='AKIA4QB2WTN5YQGLD77G',\n",
        "    aws_secret_access_key='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',\n",
        ")\n",
        "s3 = session.resource('s3')\n",
        "key = f\"{epoch}_{model_checkpoint_directory}\"\n",
        "filename = f\"{model_checkpoint_directory}.zip\"\n",
        "print(key)\n",
        "s3.meta.client.download_file(Bucket='tsd2022', Key=key, Filename=filename)"
      ],
      "metadata": {
        "id": "ygBuQXcIJtZr"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_directory = os.getcwd()\n",
        "path_to_zipfile = os.path.join(current_directory, f\"{model_checkpoint_directory}.zip\")\n",
        "path_to_output_directory = os.path.join(current_directory, f\"{model_checkpoint_directory}/\")\n",
        "shutil.unpack_archive(path_to_zipfile, path_to_output_directory)"
      ],
      "metadata": {
        "id": "YfFDiM05K--v"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-trained model checkpoints\n",
        "evaluation_model_checkpoint = os.path.join(path_to_output_directory, os.listdir(path_to_output_directory)[0])"
      ],
      "metadata": {
        "id": "8HSyQCO7acGH"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the MarianMT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(evaluation_model_checkpoint)"
      ],
      "metadata": {
        "id": "hZLsG1OcbWkX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_verbosity_eval(input_list, target_list):\n",
        "  \"\"\"\n",
        "  input: list of source & target sequences\n",
        "  output: processed source sequence based on the calculated length ratios \n",
        "  \"\"\"\n",
        "  processed_input = []\n",
        "  for input, target in zip(input_list, target_list):\n",
        "    ts_ratio = len(target)/len(input)\n",
        "    prefix = \"normal\"\n",
        "    input = prefix + \" \" + input\n",
        "    processed_input.append(input)\n",
        "  return processed_input"
      ],
      "metadata": {
        "id": "jBy5rh3OcD0f"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess MUST-C dataset\n",
        "def preprocess_test_function(examples):\n",
        "    inputs = examples[source_lang]\n",
        "    targets = examples[target_lang]\n",
        "    inputs = add_verbosity_eval(inputs, targets) # append appropriate prompts \n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "    # setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "U95eYG9ncIkC"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize raw data\n",
        "tokenized_test_dataset = raw_test_datasets.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "07f62b250c6d40228dbea2de26dc7700",
            "86980b994fe54339bf9bf78b4675258a",
            "3ef858ca822445289fe1515a21503605",
            "62db89dfb19f42bc838085c049e13ce9",
            "918d47c031434ca9b2405279ee113e22",
            "4d312ad1bdd945b2ab512478b21da3e8",
            "4082eff73a6a4916b614d53f683639a0",
            "945df4bf188240eb87b028e4963bc0f8",
            "bb3c306eb019431e9fc18c60f41a84c4",
            "eb9c58d407da4d649ffc390b4329eea9",
            "e9d97d9bf8e149518d293ef3cf3be4d7"
          ]
        },
        "id": "wbT4QG4AcTnq",
        "outputId": "d805798c-58e3-4953-9bb5-08f374baa125"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07f62b250c6d40228dbea2de26dc7700"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training procedure\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(evaluation_model_checkpoint)"
      ],
      "metadata": {
        "id": "_8vINbffcukt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, num_workers=0)"
      ],
      "metadata": {
        "id": "vkyAOOrtc62Y"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate model prediction\n",
        "predictions = []\n",
        "for batch in tqdm(test_dataloader, total=tokenized_test_dataset.shape[0]):\n",
        "  translated = model.generate(**tokenizer(batch['en'], return_tensors=\"pt\", padding=True))\n",
        "  predictions.extend([tokenizer.decode(t, skip_special_tokens=True) for t in translated])\n",
        "\n",
        "test_source, test_target = [], []\n",
        "for instance in tqdm(raw_test_datasets, total=raw_test_datasets.shape[0]):\n",
        "  test_source.append(instance[source_lang])\n",
        "  test_target.append(instance[target_lang])\n",
        "\n",
        "# generate output prediction dataframe\n",
        "df = pd.DataFrame({\n",
        "    source_lang: test_source,\n",
        "    target_lang: test_target,\n",
        "    'pred': predictions\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVX4zFcJdIDr",
        "outputId": "c2dde2f9-ae87-4feb-af3e-3def69425702"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 50/50 [01:32<00:00,  1.85s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_prediction_file = os.path.join(current_directory, f\"{model_name}-finetuned-{source_lang}-to-{target_lang}-predictions.csv\")\n",
        "df.to_csv(path_to_prediction_file, index=False)"
      ],
      "metadata": {
        "id": "-URG17FMe2rf"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload to s3\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id='AKIA4QB2WTN5YQGLD77G',\n",
        "    aws_secret_access_key='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',\n",
        ")\n",
        "s3 = session.resource('s3')\n",
        "key = f\"{model_name}-finetuned-{source_lang}-to-{target_lang}-predictions\"\n",
        "filename = path_to_prediction_file\n",
        "print(key)\n",
        "# s3.meta.client.upload_file(Bucket='tsd2022', Key=key, Filename=filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbt1EB5xgeuT",
        "outputId": "82dead4c-a3bb-40fd-f1d6-28f178e6655b"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "opus-mt-en-it-finetuned-en-to-it-predictions\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# delete checkpoint directory\n",
        "shutil.rmtree(path_to_output_directory)"
      ],
      "metadata": {
        "id": "1m9SrPVnh8eY"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete zip files\n",
        "os.remove(f\"{model_checkpoint_directory}.zip\") # model checkpoints\n",
        "os.remove(path_to_prediction_file) # csv file"
      ],
      "metadata": {
        "id": "HyVZq-oih4mu"
      },
      "execution_count": 93,
      "outputs": []
    }
  ]
}