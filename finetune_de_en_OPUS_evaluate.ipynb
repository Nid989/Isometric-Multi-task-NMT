{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "finetune de-en OPUS evaluate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSSrM/XunJsmzC8JvkVPYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nid989/Isometric-Multi-task-NMT/blob/main/finetune_de_en_OPUS_evaluate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPpIQCUTu9pf"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# un-comment below, while working on colab.\n",
        "!pip install datasets transformers sacrebleu torch sentencepiece transformers[sentencepiece] wandb boto3 --quiet "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer, MarianMTModel, MarianTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "import datasets\n",
        "import boto3\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "# from tqdm import tqdm \n",
        "import wandb\n",
        "import logging\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "1sNQTEXAwBB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data processing\n",
        "from datasets import load_dataset, load_metric\n",
        "raw_datasets = load_dataset(\"enimai/MuST-C-de\", split=[\"test\"])\n",
        "metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "SS5bSKnSwOSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset description\n",
        "print(raw_datasets)"
      ],
      "metadata": {
        "id": "luBld-SZwSPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load checkpoints from s3\n",
        "key_trained_model_checkpoints = \"3_OPUS-mt-en-de-finetuned-en-to-de\"\n",
        "model_checkpoints_directory = key_trained_model_checkpoints.split('_')\n",
        "epoch = 1\n",
        "session = boto3.Session(\n",
        "    aws_access_key_id='AKIA4QB2WTN5YQGLD77G',\n",
        "    aws_secret_access_key='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',\n",
        ")\n",
        "s3 = session.resource('s3')\n",
        "key = key_trained_model_checkpoints\n",
        "filename = f\"{model_checkpoints_directory}.zip\"\n",
        "s3.meta.client.download_file(Bucket='tsd2022', Key=key, Filename=filename)"
      ],
      "metadata": {
        "id": "4rJxVmZCawCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "current_directory = os.getcwd()\n",
        "path_to_zipfile = os.path.join(current_directory, f\"{model_checkpoints_directory}.zip\")\n",
        "path_to_output_directory = os.path.join(current_directory, f\"{model_checkpoints_directory}/\")\n",
        "shutil.unpack_archive(path_to_zipfile, current_directory)"
      ],
      "metadata": {
        "id": "yv5ZU03qbUFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pre-trained model checkpoints\n",
        "model_checkpoints = \"/content/opus-mt-de-fr-finetuned-en-to-de/checkpoint-114500\""
      ],
      "metadata": {
        "id": "03uF-V5DwfBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the MarianMT tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoints)"
      ],
      "metadata": {
        "id": "SA8Wp9-xwiZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_verbosity(input_list, target_list):\n",
        "  \"\"\"\n",
        "  input: list of source & target sequences\n",
        "  output: processed source sequence based on the calculated length ratios \n",
        "  \"\"\"\n",
        "  processed_input = []\n",
        "  for input, target in zip(input_list, target_list):\n",
        "    ts_ratio = len(target)/len(input)\n",
        "    prefix = \"normal\"\n",
        "    input = prefix + \" \" + input\n",
        "    processed_input.append(input)\n",
        "  return processed_input"
      ],
      "metadata": {
        "id": "_HRpnd8vxUGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# preprocess MUST-C dataset\n",
        "max_input_length = 128 \n",
        "max_target_length = 128\n",
        "source_lang = \"en\"\n",
        "target_lang = \"de\"\n",
        "def preprocess_function(examples):\n",
        "    inputs = examples[source_lang]\n",
        "    targets = examples[target_lang]\n",
        "    inputs = add_verbosity(inputs, targets) # append appropriate prompts \n",
        "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
        "    # setup the tokenizer for targets\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs"
      ],
      "metadata": {
        "id": "UGTxkmTjxXzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize raw data\n",
        "tokenized_test_dataset = raw_datasets[0].map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "6_dRmTpvxv8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bea598-9347-407f-c147-ec896c1dd252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/csv/enimai--MuST-C-de-11a65737a7d9f57f/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519/cache-4d6f5751adad88be.arrow\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training procedure\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoints)"
      ],
      "metadata": {
        "id": "WkukCDlFx_T5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1, num_workers=0)"
      ],
      "metadata": {
        "id": "DSGM8H8wypVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate model prediction\n",
        "predictions = []\n",
        "for batch in tqdm(test_dataloader, total=tokenized_test_dataset.shape[0]):\n",
        "  translated = model.generate(**tokenizer(batch['en'], return_tensors=\"pt\", padding=True))\n",
        "  predictions.extend([tokenizer.decode(t, skip_special_tokens=True) for t in translated])"
      ],
      "metadata": {
        "id": "VCXV2lLycdnu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}